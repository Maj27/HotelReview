{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HotelReviewSentiment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWt29sTk-hZy"
      },
      "source": [
        "## Sentiment Analysis Application of Bert (Hotel Review Rating 5 class classification)\n",
        "# This code is a modification of https://github.com/Maj27/HealthNewsReview/blob/master/Health%20News%20Review%20using%20BERT%20and%20TF2.ipynb which was orginally \n",
        "# modified from  https://github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb\n",
        "#using the Tensorflow 2.0 Keras implementation of BERT from kpe/bert-for-tf2 with the original google-research/bert weights."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT-7E2qs-7ay",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1a2d40c-c4b0-4192-aae8-e650b954eca7"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Version:  2.3.0\n",
            "Eager mode:  True\n",
            "Hub version:  0.10.0\n",
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-7xkcQp-7iL"
      },
      "source": [
        "!pip install tqdm  >> /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eweu-bEI-7k1"
      },
      "source": [
        "import os\n",
        "import math\n",
        "import datetime\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQEA5I41-7nV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "12fb5ede-7581-48bb-8179-c493b963663e"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZOxi1aiDMPr"
      },
      "source": [
        "if tf.__version__.startswith(\"1.\"):\n",
        "  tf.enable_eager_execution()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7v0Rb4yNDMSE"
      },
      "source": [
        "!pip install bert-for-tf2 >> /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BzMbfiLDMUf"
      },
      "source": [
        "import bert\n",
        "from bert import BertModelLayer\n",
        "from bert.loader import StockBertConfig, map_stock_config_to_params, load_stock_weights\n",
        "from bert.tokenization.bert_tokenization import FullTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2AjG7tbUAGE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b39c960c-171d-4147-a2a5-7759ad7e18d0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaxMVd7KDMWn"
      },
      "source": [
        "from tensorflow import keras\n",
        "import os\n",
        "import re\n",
        "\n",
        "\n",
        "def load_dataset():\n",
        "  train_file = \"/content/drive/My Drive/Data/HotelReview/sentiment_dataset_train.csv\"\n",
        "  test_file = \"/content/drive/My Drive/Data/HotelReview/sentiment_dataset_dev.csv\"\n",
        "  \n",
        "  train_df = pd.read_csv(train_file, encoding='utf-8')\n",
        "  test_df = pd.read_csv(test_file, encoding='utf-8')\n",
        "  return train_df, test_df\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4PgMmFIDaKB"
      },
      "source": [
        "import bert\n",
        "from bert import BertModelLayer\n",
        "from bert.loader import StockBertConfig, map_stock_config_to_params, load_stock_weights\n",
        "from bert import bert_tokenization\n",
        "\n",
        "\n",
        "class HotelReviewData:\n",
        "    DATA_COLUMN = \"review\"\n",
        "    LABEL_COLUMN = \"rating\"\n",
        "\n",
        "    def __init__(self, tokenizer: FullTokenizer, sample_size=None, max_seq_len=8192):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.sample_size = sample_size\n",
        "        self.max_seq_len =  0\n",
        "        train, test = load_dataset()\n",
        "        \n",
        "        train, test = map(lambda df: df.reindex(df[HotelReviewData.DATA_COLUMN].str.len().sort_values().index), \n",
        "                          [train, test])\n",
        "                \n",
        "        if sample_size is not None:\n",
        "            assert sample_size % 128 == 0\n",
        "            train, test = train.head(sample_size), test.head(sample_size)\n",
        "            # train, test = map(lambda df: df.sample(sample_size), [train, test])\n",
        "        \n",
        "        ((self.train_x, self.train_y),\n",
        "         (self.test_x, self.test_y)) = map(self._prepare, [train, test])\n",
        "\n",
        "        print(\"max seq_len\", self.max_seq_len)\n",
        "        self.max_seq_len = min(self.max_seq_len, max_seq_len)\n",
        "        ((self.train_x, self.train_x_token_types),\n",
        "         (self.test_x, self.test_x_token_types)) = map(self._pad, \n",
        "                                                       [self.train_x, self.test_x])\n",
        "\n",
        "    def _prepare(self, df):\n",
        "        x, y = [], []\n",
        "        with tqdm(total=df.shape[0], unit_scale=True) as pbar:\n",
        "            for ndx, row in df.iterrows():\n",
        "                text, label = row[HotelReviewData.DATA_COLUMN], row[HotelReviewData.LABEL_COLUMN]\n",
        "                tokens = self.tokenizer.tokenize(text)\n",
        "                tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
        "                token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "                self.max_seq_len = max(self.max_seq_len, len(token_ids))\n",
        "                x.append(token_ids)\n",
        "                y.append(int(label))\n",
        "                pbar.update()\n",
        "        return np.array(x), np.array(y)\n",
        "\n",
        "    def _pad(self, ids):\n",
        "        x, t = [], []\n",
        "        token_type_ids = [0] * self.max_seq_len\n",
        "        for input_ids in ids:\n",
        "            input_ids = input_ids[:min(len(input_ids), self.max_seq_len - 2)]\n",
        "            input_ids = input_ids + [0] * (self.max_seq_len - len(input_ids))\n",
        "            x.append(np.array(input_ids))\n",
        "            t.append(token_type_ids)\n",
        "        return np.array(x), np.array(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xf3FACEDaMU"
      },
      "source": [
        "bert_ckpt_dir=\"gs://bert_models/2018_10_18/uncased_L-12_H-768_A-12/\"\n",
        "bert_ckpt_file = bert_ckpt_dir + \"bert_model.ckpt\"\n",
        "bert_config_file = bert_ckpt_dir + \"bert_config.json\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5cdWD42DaO1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dece2993-62e5-443a-c8bc-ad461a45c7b8"
      },
      "source": [
        "\n",
        "%%time\n",
        "\n",
        "bert_model_dir=\"2018_10_18\"\n",
        "bert_model_name=\"uncased_L-12_H-768_A-12\"\n",
        "\n",
        "!mkdir -p .model .model/$bert_model_name\n",
        "\n",
        "for fname in [\"bert_config.json\", \"vocab.txt\", \"bert_model.ckpt.meta\", \"bert_model.ckpt.index\", \"bert_model.ckpt.data-00000-of-00001\"]:\n",
        "  cmd = f\"gsutil cp gs://bert_models/{bert_model_dir}/{bert_model_name}/{fname} .model/{bert_model_name}\"\n",
        "  !$cmd\n",
        "\n",
        "!ls -la .model .model/$bert_model_name"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://bert_models/2018_10_18/uncased_L-12_H-768_A-12/bert_config.json...\n",
            "/ [1 files][  313.0 B/  313.0 B]                                                \n",
            "Operation completed over 1 objects/313.0 B.                                      \n",
            "Copying gs://bert_models/2018_10_18/uncased_L-12_H-768_A-12/vocab.txt...\n",
            "/ [1 files][226.1 KiB/226.1 KiB]                                                \n",
            "Operation completed over 1 objects/226.1 KiB.                                    \n",
            "Copying gs://bert_models/2018_10_18/uncased_L-12_H-768_A-12/bert_model.ckpt.meta...\n",
            "/ [1 files][883.0 KiB/883.0 KiB]                                                \n",
            "Operation completed over 1 objects/883.0 KiB.                                    \n",
            "Copying gs://bert_models/2018_10_18/uncased_L-12_H-768_A-12/bert_model.ckpt.index...\n",
            "/ [1 files][  8.3 KiB/  8.3 KiB]                                                \n",
            "Operation completed over 1 objects/8.3 KiB.                                      \n",
            "Copying gs://bert_models/2018_10_18/uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001...\n",
            "- [1 files][420.0 MiB/420.0 MiB]                                                \n",
            "Operation completed over 1 objects/420.0 MiB.                                    \n",
            ".model:\n",
            "total 12\n",
            "drwxr-xr-x 3 root root 4096 Dec 11 04:05 .\n",
            "drwxr-xr-x 1 root root 4096 Dec 11 04:05 ..\n",
            "drwxr-xr-x 2 root root 4096 Dec 11 04:05 uncased_L-12_H-768_A-12\n",
            "\n",
            ".model/uncased_L-12_H-768_A-12:\n",
            "total 431244\n",
            "drwxr-xr-x 2 root root      4096 Dec 11 04:05 .\n",
            "drwxr-xr-x 3 root root      4096 Dec 11 04:05 ..\n",
            "-rw-r--r-- 1 root root       313 Dec 11 04:05 bert_config.json\n",
            "-rw-r--r-- 1 root root 440425712 Dec 11 04:05 bert_model.ckpt.data-00000-of-00001\n",
            "-rw-r--r-- 1 root root      8528 Dec 11 04:05 bert_model.ckpt.index\n",
            "-rw-r--r-- 1 root root    904243 Dec 11 04:05 bert_model.ckpt.meta\n",
            "-rw-r--r-- 1 root root    231508 Dec 11 04:05 vocab.txt\n",
            "CPU times: user 58.2 ms, sys: 52.4 ms, total: 111 ms\n",
            "Wall time: 15.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSIuu6ifDaRR"
      },
      "source": [
        "bert_ckpt_dir    = os.path.join(\".model/\",bert_model_name)\n",
        "bert_ckpt_file   = os.path.join(bert_ckpt_dir, \"bert_model.ckpt\")\n",
        "bert_config_file = os.path.join(bert_ckpt_dir, \"bert_config.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVVTRJxFDaTz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25550271-388f-492c-98c6-5e5449246793"
      },
      "source": [
        "%%time\n",
        "\n",
        "tokenizer = FullTokenizer(vocab_file=os.path.join(bert_ckpt_dir, \"vocab.txt\"))\n",
        "data = HotelReviewData(tokenizer, \n",
        "                       sample_size=10*256*2,#5000, \n",
        "                       max_seq_len=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5.12k/5.12k [00:03<00:00, 1.41kit/s]\n",
            "100%|██████████| 5.12k/5.12k [00:06<00:00, 819it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "max seq_len 209\n",
            "CPU times: user 10.5 s, sys: 137 ms, total: 10.6 s\n",
            "Wall time: 13.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8XjRyboDaWW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bffdd33-a15e-4ca8-d024-34ca2cbd43ab"
      },
      "source": [
        "print(\"            train_x\", data.train_x.shape)\n",
        "print(\"train_x_token_types\", data.train_x_token_types.shape)\n",
        "print(\"            train_y\", data.train_y.shape)\n",
        "\n",
        "print(\"             test_x\", data.test_x.shape)\n",
        "\n",
        "print(\"        max_seq_len\", data.max_seq_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            train_x (5120, 128)\n",
            "train_x_token_types (5120, 128)\n",
            "            train_y (5120,)\n",
            "             test_x (5120, 128)\n",
            "        max_seq_len 128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QartoP2dDMY9"
      },
      "source": [
        "def flatten_layers(root_layer):\n",
        "    if isinstance(root_layer, keras.layers.Layer):\n",
        "        yield root_layer\n",
        "    for layer in root_layer._layers:\n",
        "        for sub_layer in flatten_layers(layer):\n",
        "            yield sub_layer\n",
        "\n",
        "\n",
        "def freeze_bert_layers(l_bert):\n",
        "    \"\"\"\n",
        "    Freezes all but LayerNorm and adapter layers - see arXiv:1902.00751.\n",
        "    \"\"\"\n",
        "    for layer in flatten_layers(l_bert):\n",
        "        if layer.name in [\"LayerNorm\", \"adapter-down\", \"adapter-up\"]:\n",
        "            layer.trainable = True\n",
        "        elif len(layer._layers) == 0:\n",
        "            layer.trainable = False\n",
        "        l_bert.embeddings_layer.trainable = False\n",
        "\n",
        "\n",
        "def create_learning_rate_scheduler(max_learn_rate=5e-5,\n",
        "                                   end_learn_rate=1e-7,\n",
        "                                   warmup_epoch_count=10,\n",
        "                                   total_epoch_count=90):\n",
        "\n",
        "    def lr_scheduler(epoch):\n",
        "        if epoch < warmup_epoch_count:\n",
        "            res = (max_learn_rate/warmup_epoch_count) * (epoch + 1)\n",
        "        else:\n",
        "            res = max_learn_rate*math.exp(math.log(end_learn_rate/max_learn_rate)*(epoch-warmup_epoch_count+1)/(total_epoch_count-warmup_epoch_count+1))\n",
        "        return float(res)\n",
        "    learning_rate_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1)\n",
        "\n",
        "    return learning_rate_scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJf9UHyiDMbh"
      },
      "source": [
        "def create_model(max_seq_len, adapter_size=64):\n",
        "  \"\"\"Creates a classification model.\"\"\"\n",
        "\n",
        "  #adapter_size = 64  # see - arXiv:1902.00751\n",
        "\n",
        "  # create the bert layer\n",
        "  with tf.io.gfile.GFile(bert_config_file, \"r\") as reader:\n",
        "      bc = StockBertConfig.from_json_string(reader.read())\n",
        "      bert_params = map_stock_config_to_params(bc)\n",
        "      bert_params.adapter_size = adapter_size\n",
        "      bert = BertModelLayer.from_params(bert_params, name=\"bert\")\n",
        "        \n",
        "  input_ids      = keras.layers.Input(shape=(max_seq_len,), dtype='int32', name=\"input_ids\")\n",
        "  # token_type_ids = keras.layers.Input(shape=(max_seq_len,), dtype='int32', name=\"token_type_ids\")\n",
        "  # output         = bert([input_ids, token_type_ids])\n",
        "  output         = bert(input_ids)\n",
        "\n",
        "  print(\"bert shape\", output.shape)\n",
        "  cls_out = keras.layers.Lambda(lambda seq: seq[:, 0, :])(output)\n",
        "  cls_out = keras.layers.Dropout(0.5)(cls_out)\n",
        "  logits = keras.layers.Dense(units=768, activation=\"tanh\")(cls_out)\n",
        "  logits = keras.layers.Dropout(0.5)(logits)\n",
        "  logits = keras.layers.Dense(units=2, activation=\"softmax\")(logits)\n",
        "\n",
        "  # model = keras.Model(inputs=[input_ids, token_type_ids], outputs=logits)\n",
        "  # model.build(input_shape=[(None, max_seq_len), (None, max_seq_len)])\n",
        "  model = keras.Model(inputs=input_ids, outputs=logits)\n",
        "  model.build(input_shape=(None, max_seq_len))\n",
        "\n",
        "  # load the pre-trained model weights\n",
        "  load_stock_weights(bert, bert_ckpt_file)\n",
        "\n",
        "  # freeze weights if adapter-BERT is used\n",
        "  if adapter_size is not None:\n",
        "      freeze_bert_layers(bert)\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.Adam(),\n",
        "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")])\n",
        "\n",
        "  model.summary()\n",
        "        \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bKsRh0BDMdu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd04d9d0-9f60-4799-d8c3-f60e4c498023"
      },
      "source": [
        "adapter_size = None # use None to fine-tune all of BERT\n",
        "model = create_model(data.max_seq_len, adapter_size=adapter_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert shape (None, 128, 768)\n",
            "Done loading 196 BERT weights from: .model/uncased_L-12_H-768_A-12/bert_model.ckpt into <bert.model.BertModelLayer object at 0x7fa7a0af8d68> (prefix:bert). Count of weights not found in the checkpoint was: [0]. Count of weights with mismatched shape: [0]\n",
            "Unused weights from checkpoint: \n",
            "\tbert/embeddings/token_type_embeddings\n",
            "\tbert/pooler/dense/bias\n",
            "\tbert/pooler/dense/kernel\n",
            "\tcls/predictions/output_bias\n",
            "\tcls/predictions/transform/LayerNorm/beta\n",
            "\tcls/predictions/transform/LayerNorm/gamma\n",
            "\tcls/predictions/transform/dense/bias\n",
            "\tcls/predictions/transform/dense/kernel\n",
            "\tcls/seq_relationship/output_bias\n",
            "\tcls/seq_relationship/output_weights\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_ids (InputLayer)       [(None, 128)]             0         \n",
            "_________________________________________________________________\n",
            "bert (BertModelLayer)        (None, 128, 768)          108890112 \n",
            "_________________________________________________________________\n",
            "lambda (Lambda)              (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 768)               590592    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 1538      \n",
            "=================================================================\n",
            "Total params: 109,482,242\n",
            "Trainable params: 109,482,242\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39iDr9jaDMfz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 940
        },
        "outputId": "31f5a103-261e-4efa-c775-f194f514b940"
      },
      "source": [
        "%%time\n",
        "\n",
        "log_dir = \".log/hotel_reviews/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%s\")\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "\n",
        "total_epoch_count = 20\n",
        "# model.fit(x=(data.train_x, data.train_x_token_types), y=data.train_y,\n",
        "model.fit(x=data.train_x, y=data.train_y,\n",
        "          validation_split=0.1,\n",
        "          batch_size=48,\n",
        "          shuffle=True,\n",
        "          epochs=total_epoch_count,\n",
        "          callbacks=[create_learning_rate_scheduler(max_learn_rate=1e-5,\n",
        "                                                    end_learn_rate=1e-7,\n",
        "                                                    warmup_epoch_count=20,\n",
        "                                                    total_epoch_count=total_epoch_count),\n",
        "                     keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True),\n",
        "                     tensorboard_callback])\n",
        "\n",
        "model.save_weights('./hotel_reviews.h5', overwrite=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 5.000000000000001e-07.\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-0a326817213d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\nlog_dir = \".log/hotel_reviews/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%s\")\\ntensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir)\\n\\ntotal_epoch_count = 20\\n# model.fit(x=(data.train_x, data.train_x_token_types), y=data.train_y,\\nmodel.fit(x=data.train_x, y=data.train_y,\\n          validation_split=0.1,\\n          batch_size=48,\\n          shuffle=True,\\n          epochs=total_epoch_count,\\n          callbacks=[create_learning_rate_scheduler(max_learn_rate=1e-5,\\n                                                    end_learn_rate=1e-7,\\n                                                    warmup_epoch_count=20,\\n                                                    total_epoch_count=total_epoch_count),\\n                     keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True),\\n                     tensorboard_callback])\\n\\nmodel.save_weights(\\'./hotel_reviews.h5\\', overwrite=True)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted:  OOM when allocating tensor with shape[48,128,3072] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/functional_1/bert/encoder/layer_9/intermediate/Pow/Pow (defined at <timed exec>:17) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[gradient_tape/functional_1/bert/embeddings/word_embeddings/embedding_lookup/Reshape/_32]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  OOM when allocating tensor with shape[48,128,3072] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/functional_1/bert/encoder/layer_9/intermediate/Pow/Pow (defined at <timed exec>:17) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_21252]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradient_tape/functional_1/bert/encoder/layer_9/intermediate/Pow/Pow:\n functional_1/bert/encoder/layer_9/intermediate/BiasAdd (defined at /usr/local/lib/python3.6/dist-packages/bert/transformer.py:179)\n\nInput Source operations connected to node gradient_tape/functional_1/bert/encoder/layer_9/intermediate/Pow/Pow:\n functional_1/bert/encoder/layer_9/intermediate/BiasAdd (defined at /usr/local/lib/python3.6/dist-packages/bert/transformer.py:179)\n\nFunction call stack:\ntrain_function -> train_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjiCUgPWEn21"
      },
      "source": [
        "%%time \n",
        "\n",
        "model = create_model(data.max_seq_len, adapter_size=None)\n",
        "model.load_weights(\"hotel_reviews.h5\")\n",
        "\n",
        "_, train_acc = model.evaluate(data.train_x, data.train_y)\n",
        "_, test_acc = model.evaluate(data.test_x, data.test_y)\n",
        "\n",
        "print(\"train acc\", train_acc)\n",
        "print(\" test acc\", test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEM9rJ63mesY"
      },
      "source": [
        "test_reviews = data.test_x\n",
        "test_ratings = data.test_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj-BgQOmjv-T"
      },
      "source": [
        "predictions = model.predict(test_reviews).argmax(axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiNpWoanEn50"
      },
      "source": [
        "import collections\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "def evaluation(y_test, y_pred):\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision=precision_score(y_test, y_pred, average='micro')\n",
        "    recall=recall_score(y_test, y_pred, average='micro')\n",
        "    f1=f1_score(y_test, y_pred, average='micro')\n",
        "    \n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "\n",
        "def print_evlauation(y_test, y_pred):\n",
        "    accuracy, precision, recall, f1 = evaluation(y_test, y_pred)\n",
        "    print('accuracy {:.2f}, precision {:.2f}, recall {:.2f}, f1 {:.2f}'.format(accuracy, precision, recall, f1))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlq2eMK7En-R"
      },
      "source": [
        "\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "print('Confusion Matrix:')\r\n",
        "print(confusion_matrix(list(test_ratings), predictions))\r\n",
        "print('')\r\n",
        "print('Evaluation Metrics')\r\n",
        "print_evlauation(list(test_ratings), predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTSCtfIwEoDG"
      },
      "source": [
        "test_ratings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swEbc6_8EoGd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTvMU9_vEoBD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htH-QeNp-3WM"
      },
      "source": [
        ""
      ]
    }
  ]
}